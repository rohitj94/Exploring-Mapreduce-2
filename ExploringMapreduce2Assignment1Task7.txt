import java.io.DataInput;

import java.io.DataOutput;

import org.apache.hadoop.io.Text;

import java.io.IOException;

import org.apache.hadoop.io.WritableComparable;

public class Company implements WritableComparable<Company>

{

   Text company = new Text();

   Text product = new Text();

   Text size = new Text();

   
   public Company()

   {

	   this.company = new Text();

	   this.product = new Text();

	   this.size = new Text();

   }

   
   public Text getSize()

    {

		return size;
    }


	public void setSize(Text size)

	{

		this.size = size;

	}

	
	public void setProduct(Text prod)

   {

	   this.product = prod;

   }

   
   public void setCompany(Text comp)

   {

	   this.company = comp;

   }

   
   public Text getProduct()

   {

	   return product;
 
   }

   
   public Text getCompany()

   {
	   return company;
   }

   
   public void readFields(DataInput in) throws IOException
   {
	   this.company.readFields(in);
	   this.product.readFields(in);
	   this.size.readFields(in);
   }

   
   public void write(DataOutput out) throws IOException
   {
	   company.write(out);
	   product.write(out);
	   size.write(out);
   }

   
   public int hashCode()

   {
	   return company.hashCode()*13;

   }

   
   public boolean equals(Object o)

   {

	 if(o instanceof Company)

	 {

		Company other = (Company)o;

	    return this.company.equals(other.company) && this.product.equals(other.product) && this.size.equals(other.size);
	 }

	 return false;

   }

	   
	   public int compareTo(Company other)

	   {

		   int result = this.company.compareTo(other.company);
			  
		   if(result!=0)
			  return result;
		   else if(this.product.compareTo(other.product) != 0)
			  return this.product.compareTo(other.product);
		   else	  
	          return this.size.compareTo(other.size);
	   }
   
   public String toString()
   {
	   return company.toString() + " " + product.toString() + " " + size.toString();
   }
   
   public void set(Text companyname, Text productname, Text size)
   {
	  this.company = companyname;
	  this.product = productname;
	  this.size = size;
   }
   
   public String get()
   {
	   return company + "" + product + "" + size;
   }
}




Mapper

------



import java.io.IOException;

import org.apache.hadoop.io.Text;

import org.apache.hadoop.io.LongWritable;

import org.apache.hadoop.io.NullWritable;

import org.apache.hadoop.io.IntWritable;

import org.apache.hadoop.mapreduce.Mapper;



class CompanyMapper extends Mapper<LongWritable, Text, Text, IntWritable>

{
  

  Text companyName = new Text();

  Text productName = new Text();


  
IntWritable in = new IntWritable(1);



  public void map(LongWritable offset, Text value, Context context) throws IOException, InterruptedException

  {

    String[] line = value.toString().split("\\|");
	    companyName.set(line[0]);

    productName.set(line[1]);


    if(!("NA".equalsIgnoreCase(companyName.toString()) || "NA".equalsIgnoreCase(productName.toString())))

    {
      context.write(companyName,in);

    }
}

}




SortComparator

--------------


import org.apache.hadoop.io.WritableComparator;

import org.apache.hadoop.io.WritableComparable;


public class CompanyProductComparator extends WritableComparator
{
	protected CompanyProductComparator()

	   {

		   super(Company.class, true);

	   }

	
	public int compare(WritableComparable w1, WritableComparable w2)

        {

	 Company c1 = (Company) w1;

	 Company c2 = (Company) w2;

		 
	 int result = c1.getCompany().compareTo(c2.getCompany());

	 
	 if(result != 0)

	   {

		 return c1.getCompany().compareTo(c2.getCompany());
	   }

	 else if(c1.getProduct().compareTo(c2.getProduct()) != 0)
	    {
		 return c1.getProduct().compareTo(c2.getProduct());
	    }
	 else

		return -1 * c1.getSize().compareTo(c2.getSize());
         }
}





Reducer

-------


import java.io.IOException;

import org.apache.hadoop.io.Text;

import org.apache.hadoop.io.LongWritable;

import org.apache.hadoop.io.IntWritable;

import org.apache.hadoop.mapreduce.Reducer;

import java.lang.Iterable;

class CompanyReducer extends Reducer<Text, IntWritable, Text, IntWritable>

{
  
  
    IntWritable in = new IntWritable();


  

  public void reduce(Text key, Iterable<IntWritable> Units, Context context) 
		  throws IOException, InterruptedException

  {
  
     int sum = 0;

       
for(IntWritable value : Units)

       {

    	  sum = sum + value.get();
 
      }
     
     context.write(key, new IntWritable(sum));

  }

}




Driver

-------




import org.apache.hadoop.fs.Path;

import org.apache.hadoop.conf.*;

import org.apache.hadoop.mapreduce.Job;

import org.apache.hadoop.mapreduce.Mapper;

import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;

import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

import org.apache.hadoop.util.Tool;

import org.apache.hadoop.util.ToolRunner;

import org.apache.hadoop.io.Text;

import org.apache.hadoop.io.IntWritable;

import org.apache.hadoop.io.NullWritable;





public class TelevisionDriver extends Configured implements Tool {
    @SuppressWarnings("deprecation")

    
    
    public int run(String[] args) throws Exception
 {

        Configuration conf = new Configuration();

        Job job = new Job(conf, "TVDetails");

        job.setJarByClass(TelevisionDriver.class);

        

job.setMapperClass(CompanyMapper.class);
        job.setReducerClass(CompanyReducer.class);

        job.setsortComparatorClass(CompanyComparator.class);


        job.setCombinerClass(CompanyReducer.class);

        job.setOutputKeyClass(Text.class);

        job.setOutputValueClass(IntWritable.class);
        
        

        job.setInputFormatClass(TextInputFormat.class);

        job.setOutputFormatClass(TextOutputFormat.class);


        FileInputFormat.addInputPath(job, new Path(args[0]));

        FileOutputFormat.setOutputPath(job,new Path(args[1]));

        
        return job.waitForCompletion(true) ? 0 : 1;
        
 }
    
    

        public static void main(String args[]) throws Exception
    {
    	int exitCode = ToolRunner.run(new TelevisionDriver(), args);
    }
}



Execution

---------



hadoop jar EM1A2.jar /television.txt /EM1A2



Result

-------



hadoop fs -cat /EM1A2/part-r-00000
